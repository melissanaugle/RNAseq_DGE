scale_fill_gradient2(low="blue", mid="black", high="orange", midpoint=3.9,    limits=c(-3,19)) +
ylab("Genes") +
xlab("") +
ggtitle("") +
theme(legend.title = element_text(size = 10),
legend.text = element_text(size = 12),
plot.title = element_text(size=10),
axis.title = element_text(size=14,face="bold"),
axis.text.x = element_text(angle = 90, hjust = 1),
axis.text.y = element_text(angle = 20, size = 0))+
labs(fill = "Log CPM")
g
ggsave("Figures/glmlogcpm_FDR0.5_COCOheatvcontrol.png",plot=g)
data <- read.csv("data/glmlogcpm_FDR0.5_allheatvcontrol.csv", header=TRUE)
head(data)
nrow(data) #7021
#Check for row duplicates
data[duplicated(data) | duplicated(data, fromLast=TRUE), ]
duplicated(data)
#Re-organize data
#cluster rows
row.order <- hclust(dist(data))$order
#cluster columns by sample order
col.order <-c(1,3,5,7,9,11,12,14,17,19,21,2,4,6,8,10,13,15,16,18,20,22)
#re-order matrix according to clustering
dat_clust <- data[row.order, col.order] # re-order matrix according to clustering
#reshape into data frame
df_molten_dat <- melt(as.matrix(dat_clust))
names(df_molten_dat)[c(1:2)] <- c("Trinity_ID", "treatment")
df_molten_dat
#Find min and max of value column in data frame to determine range of heatmap
max(df_molten_dat$value)
min(df_molten_dat$value)
mean(df_molten_dat$value)
IQR(df_molten_dat$value)
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("edgeR")
#install.packages("statmod")
library("edgeR")
library("statmod")
library("data.table")
setwd("~/Desktop/GitHub/RNAseq_DGE")
nrow(tagsTblANOVA.one.allheatvcontrol.filt)
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("edgeR")
#install.packages("statmod")
library("edgeR")
library("statmod")
library("data.table")
setwd("~/Desktop/GitHub/RNAseq_DGE")
#Import gene count data and view the first few rows
#had to add 'gene' to first header row on original txt file to prevent weird error
countsTable <- read.table(file="RSEM.isoform.counts.matrix.txt", row.names="gene", sep="\t", header=TRUE)
head(countsTable)
#import grouping factor and create samples group matrix
reps <- read.table("replicates.txt", header = T)
group <- factor(paste(reps$site,reps$treatment,sep="."))
cbind(reps,Group=group)
#create 'DGE list' object
#don't include group yet? #but r blog says to include so we include
y <- DGEList(counts=countsTable, group = group)
#MAKE SURE SAME ORDER ON REPS SHEET AS IN COUNTS MATRIX
colnames(y) <- reps$sample
#filter out lowly expressed genes
keep <- filterByExpr(y)
y <- y[keep,,keep.lib.sizes=FALSE]
#view summary of normalized counts
summary(keep)
#normalize library sizes (use trimmed mean m values to eliminate composition biases)
y <- calcNormFactors(y)
#not included in Jacoby's code
#write normalized
normList <- cpm(y, normalized.lib.sizes = T)
nrow(normList)
#write.table(normList, file = "data/glmQLF_normalizedCounts.csv", sep=",", row.names=T)
#make list for heatmap of log counts per million
logcpm <- cpm(y, log=TRUE)
head(logcpm)
nrow(logcpm)
#write.table(logcpm, file = "data/glmlogcpm.csv", sep=",", row.names=T)
#create design object with levels of treatments
design <- model.matrix(~0 + group)
colnames(design) <- levels(group)
design #looks good!
fit <- glmQLFit(y, design, robust = T) #Setting robust=TRUE in glmQLFit is strongly recommended
#if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
#BiocManager::install("edgeR")
#install.packages("statmod")
library("edgeR")
library("statmod")
library("data.table")
setwd("~/Desktop/GitHub/RNAseq_DGE")
#Import gene count data and view the first few rows
#had to add 'gene' to first header row on original txt file to prevent weird error
countsTable <- read.table(file="RSEM.isoform.counts.matrix.txt", row.names="gene", sep="\t", header=TRUE)
head(countsTable)
#import grouping factor and create samples group matrix
reps <- read.table("replicates.txt", header = T)
group <- factor(paste(reps$site,reps$treatment,sep="."))
cbind(reps,Group=group)
#create 'DGE list' object
#don't include group yet? #but r blog says to include so we include
y <- DGEList(counts=countsTable, group = group)
#MAKE SURE SAME ORDER ON REPS SHEET AS IN COUNTS MATRIX
colnames(y) <- reps$sample
#filter out lowly expressed genes
keep <- filterByExpr(y)
y <- y[keep,,keep.lib.sizes=FALSE]
#view summary of normalized counts
summary(keep)
#normalize library sizes (use trimmed mean m values to eliminate composition biases)
y <- calcNormFactors(y)
#not included in Jacoby's code
#write normalized
normList <- cpm(y, normalized.lib.sizes = T)
nrow(normList)
#write.table(normList, file = "data/glmQLF_normalizedCounts.csv", sep=",", row.names=T)
#make list for heatmap of log counts per million
logcpm <- cpm(y, log=TRUE)
head(logcpm)
nrow(logcpm)
#write.table(logcpm, file = "data/glmlogcpm.csv", sep=",", row.names=T)
#create design object with levels of treatments
design <- model.matrix(~0 + group)
colnames(design) <- levels(group)
design #looks good!
fit <- glmQLFit(y, design, robust = T) #Setting robust=TRUE in glmQLFit is strongly recommended
#Import gene count data and view the first few rows
#had to add 'gene' to first header row on original txt file to prevent weird error
countsTable <- read.table(file="RSEM.isoform.counts.matrix.txt", row.names="gene", sep="\t", header=TRUE)
head(countsTable)
#import grouping factor and create samples group matrix
reps <- read.table("replicates.txt", header = T)
group <- factor(paste(reps$site,reps$treatment,sep="."))
cbind(reps,Group=group)
#create 'DGE list' object
#don't include group yet? #but r blog says to include so we include
y <- DGEList(counts=countsTable, group = group)
#MAKE SURE SAME ORDER ON REPS SHEET AS IN COUNTS MATRIX
colnames(y) <- reps$sample
#filter out lowly expressed genes
keep <- filterByExpr(y)
y <- y[keep,,keep.lib.sizes=FALSE]
#view summary of normalized counts
summary(keep)
#normalize library sizes (use trimmed mean m values to eliminate composition biases)
y <- calcNormFactors(y)
#not included in Jacoby's code
#write normalized
normList <- cpm(y, normalized.lib.sizes = T)
nrow(normList)
#write.table(normList, file = "data/glmQLF_normalizedCounts.csv", sep=",", row.names=T)
#make list for heatmap of log counts per million
logcpm <- cpm(y, log=TRUE)
head(logcpm)
nrow(logcpm)
#write.table(logcpm, file = "data/glmlogcpm.csv", sep=",", row.names=T)
nrow(logcpm)
#create design object with levels of treatments
design <- model.matrix(~0 + group)
colnames(design) <- levels(group)
design #looks good!
fit <- glmQLFit(y, design, robust = T) #Setting robust=TRUE in glmQLFit is strongly recommended
#recommended to estimate dispersion for GLM
y <- estimateDisp(y,design, robust = T)
y$common.dispersion #0.32755 is that good??
#visualize with BCV plot
jpeg("Figures/glmQLF_plotBCV.jpg")
plotBCV(y)
dev.off()
fit <- glmQLFit(y, design, robust = T) #Setting robust=TRUE in glmQLFit is strongly recommended
head(fit$coefficients)
#plot to QL dispersions and write file
jpeg("Figures/glmQLF_plotQLDisp.jpg")
plotQLDisp(fit)
dev.off()
con <- makeContrasts(
Coco_HvE = CoconutPoint.Heat_35 - CoconutPoint.Control_28,
Alu_HvE = Fagaalu.Heat_35 - Fagaalu.Control_28,
Tele_HvE = Fagatele.Heat_35 - Fagatele.Control_28, levels = design)
#The QL F-test is then applied to identify genes that are DE among the three groups. This combines the three pairwise comparisons into a single F-statistic and p-value. The top set of significant genes can be displayed with topTags.
anov <- glmQLFTest(fit, contrast=con)
topTags(anov)
# anov should show DGE bw control and heat common to all 3 sites. Meaning these are genes that are common to the heat stress response, regardless of pollution level
#If all three contrasts are present in the contrast matrix, then only the log-fold changes of the first two contrasts are shown in the output of topTags.
is.de <- decideTestsDGE(anov, p.value=0.05)
summary(is.de)
tagsTblANOVA.one.allheatvcontrol <- topTags(anov, n = nrow(anov$table))$table
nrow(tagsTblANOVA.one.allheatvcontrol) #15007 = all
tagsTblANOVA.one.allheatvcontrol.filt <- tagsTblANOVA.one.allheatvcontrol[tagsTblANOVA.one.allheatvcontrol$FDR <= 0.05,]
nrow(tagsTblANOVA.one.allheatvcontrol.filt)
#write.table(tagsTblANOVA.one.allheatvcontrol.filt, file="data/DEcontigs_edger_glm/tagsTblANOVA.one.allheatvcontrol_FDR0.05.csv", sep=",", row.names=TRUE)
#make list for heatmap of log counts per million
logcpm <- cpm(y, log=TRUE, prior.count = T)
head(logcpm)
nrow(logcpm)
#write.table(logcpm, file = "data/glmlogcpm.csv", sep=",", row.names=T)
#write file for heatmap
logcpm_FDR0.5_allheatvcontrol <- logcpm[c(row.names(tagsTblANOVA.one.allheatvcontrol.filt)), ]
nrow(tagsTblANOVA.one.allheatvcontrol.filt)
nrow(logcpm_FDR0.5_allheatvcontrol)
#write.table(logcpm_FDR0.5_allheatvcontrol, file = "data/glmlogcpm_FDR0.5_allheatvcontrol.csv", sep=",", row.names=T)
nrow(logcpm_FDR0.5_allheatvcontrol)
nrow(tagsTblANOVA.one.allheatvcontrol.filt)
nrow(tagsTblANOVA.one.allheatvcontrol.filt)
con <- makeContrasts(CoconutPoint.Heat_35 - CoconutPoint.Control_28, levels=design)
qlf <- glmQLFTest(fit, contrast=con)
#The top set of most significant genes can be examined with topTags. Multiplicity correction is performed by applying the Benjamini-Hochberg method on the p-values, to control the false discovery rate (FDR).
topTags(qlf)
#The total number of DE genes in each direction at a FDR of 5% can be examined with decideTestsDGE.
is.de <- decideTestsDGE(qlf, p.value=0.05)
summary(is.de)
#plotSmear(qlf, de.tags=rownames(qlf)[is.de!=0])
tr <- glmTreat(fit, contrast=con, lfc=log2(1.2))
topTags(tr)
is.de <- decideTestsDGE(tr, p.value=0.05)
summary(is.de)
#plotSmear(tr, de.tags=rownames(tr)[is.de!=0])
tagsTblANOVA.one.cocohve <- topTags(qlf, n = nrow(anov$table))$table
nrow(tagsTblANOVA.one.cocohve)
tagsTblANOVA.one.cocohve.filt <- tagsTblANOVA.one.cocohve[tagsTblANOVA.one.cocohve$FDR <= 0.05,]
nrow(tagsTblANOVA.one.cocohve.filt)
nrow(tagsTblANOVA.one.cocohve.filt)
con <- makeContrasts(Fagaalu.Heat_35 - Fagaalu.Control_28, levels=design)
qlf <- glmQLFTest(fit, contrast=con)
topTags(qlf)
is.de <- decideTestsDGE(qlf, p.value=0.05)
summary(is.de)
#plotSmear(qlf, de.tags=rownames(qlf)[is.de!=0])
tr <- glmTreat(fit, contrast=con, lfc=log2(1.2))
topTags(tr)
is.de <- decideTestsDGE(tr, p.value=0.05)
summary(is.de)
#plotSmear(tr, de.tags=rownames(tr)[is.de!=0])
tagsTblANOVA.one.aluhve <- topTags(qlf, n = nrow(anov$table))$table
tagsTblANOVA.one.aluhve.filt <- tagsTblANOVA.one.aluhve[tagsTblANOVA.one.aluhve$FDR <= 0.05,]
write.table(tagsTblANOVA.one.aluhve.filt, file="data/DEcontigs_edger_glm/tagsTblANOVA.one.aluheatvcontrolFDR0.05.csv", sep=",", row.names=TRUE)
nrow(tagsTblANOVA.one.aluhve.filt)
#write file for heatmap
logcpm_FDR0.5_ALUheatvcontrol <- logcpm[c(row.names(tagsTblANOVA.one.aluhve.filt)), ]
nrow(tagsTblANOVA.one.aluhve.filt)
nrow(logcpm_FDR0.5_ALUheatvcontrol)
write.table(logcpm_FDR0.5_ALUheatvcontrol, file = "data/glmlogcpm_FDR0.5_ALUheatvcontrol.csv", sep=",", row.names=T)
data_alu <- read.csv("data/glmlogcpm_FDR0.5_ALUheatvcontrol.csv", header=TRUE)
head(data_alu)
data_alu <- data_alu[,c(1:8)]
row.order <- hclust(dist(data_alu))$order
col.order <-c(1,3,5,7,2,4,6,8)
dat_clust <- data_alu[row.order, col.order]
df_molten_dat <- melt(as.matrix(dat_clust))
names(df_molten_dat)[c(1:2)] <- c("Trinity_ID", "treatment")
df_molten_dat
g<-ggplot(df_molten_dat, aes(x=treatment,y=Trinity_ID)) +
geom_tile(aes(fill = value)) +
scale_fill_gradient2(low="blue", mid="black", high="orange", midpoint=3.9,    limits=c(-3,19)) +
ylab("Genes") +
xlab("") +
ggtitle("") +
theme(legend.title = element_text(size = 10),
legend.text = element_text(size = 12),
plot.title = element_text(size=10),
axis.title = element_text(size=14,face="bold"),
axis.text.x = element_text(angle = 90, hjust = 1),
axis.text.y = element_text(angle = 20, size = 0))+
labs(fill = "Log CPM")
g
ggsave("Figures/glmlogcpm_FDR0.5_ALUheatvcontrol.png",plot=g)
con <- makeContrasts(Fagatele.Heat_35 - Fagatele.Control_28, levels=design)
qlf <- glmQLFTest(fit, contrast=con)
topTags(qlf)
is.de <- decideTestsDGE(qlf, p.value=0.05)
summary(is.de)
#plotSmear(qlf, de.tags=rownames(qlf)[is.de!=0])
tr <- glmTreat(fit, contrast=con, lfc=log2(1.2))
topTags(tr)
is.de <- decideTestsDGE(tr, p.value=0.05)
summary(is.de)
#plotSmear(tr, de.tags=rownames(tr)[is.de!=0])
tagsTblANOVA.one.telehve <- topTags(qlf, n = nrow(anov$table))$table
nrow(tagsTblANOVA.one.telehve)
tagsTblANOVA.one.telehve.filt <- tagsTblANOVA.one.telehve[tagsTblANOVA.one.telehve$FDR <= 0.05,]
nrow(tagsTblANOVA.one.telehve.filt)
#write file for heatmap
logcpm_FDR0.5_TELEheatvcontrol <- logcpm[c(row.names(tagsTblANOVA.one.telehve.filt)), ]
nrow(tagsTblANOVA.one.telehve.filt)
nrow(logcpm_FDR0.5_TELEheatvcontrol)
write.table(logcpm_FDR0.5_TELEheatvcontrol, file = "data/glmlogcpm_FDR0.5_TELEheatvcontrol.csv", sep=",", row.names=T)
data_tele <- read.csv("data/glmlogcpm_FDR0.5_TELEheatvcontrol.csv", header=TRUE)
data_tele <- read.csv("data/glmlogcpm_FDR0.5_TELEheatvcontrol.csv", header=TRUE)
head(data_tele)
data_tele <- data_tele[,c(1:8)]
row.order <- hclust(dist(data_tele))$order
col.order <-c(1,3,5,7,2,4,6,8)
dat_clust <- data_tele[row.order, col.order]
df_molten_dat <- melt(as.matrix(dat_clust))
names(df_molten_dat)[c(1:2)] <- c("Trinity_ID", "treatment")
df_molten_dat
g<-ggplot(df_molten_dat, aes(x=treatment,y=Trinity_ID)) +
geom_tile(aes(fill = value)) +
scale_fill_gradient2(low="blue", mid="black", high="orange", midpoint=3.9,    limits=c(-3,19)) +
ylab("Genes") +
xlab("") +
ggtitle("") +
theme(legend.title = element_text(size = 10),
legend.text = element_text(size = 12),
plot.title = element_text(size=10),
axis.title = element_text(size=14,face="bold"),
axis.text.x = element_text(angle = 90, hjust = 1),
axis.text.y = element_text(angle = 20, size = 0))+
labs(fill = "Log CPM")
g
ggsave("Figures/glmlogcpm_FDR0.5_TELEheatvcontrol.png",plot=g)
#change this to your working directory
setwd(dir = "~/Desktop/GitHub/CBASS_bleachingdata/")
rm( list = ls())
graphics.off()
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(mosaic)
library(car)
library(lmerTest)
library(emmeans)
library(ggpubr)
library(tidyr)
data <- read.csv("raw data sheets/MasterASData.csv")
head(data)
data$Time.point <- as.character(data$Time.point)
#insert "field" into timepoint for field collected corals
data$Time.point[data$Ramp == "Field"] <- "Field"
#first subset only recovery data (time point 2)
#recovery/time point2 data more likely to show diffs
data_recov <- data %>%
filter(data$Time.point == "Recovery")
#remove NAs
data_recov <- data_recov[!is.na(data_recov$AverageRed), ]
# Analysis of variance (2-way) ANOVA CBASS
red.CBASS.lm <- lm(AverageRed ~ Site * Ramp, data = data_norm)
data <- data_recov
data$Coral.Watch.Color1 <- NULL
data$Coral.Watch.Color2 <- NULL
data$Coral.Watch.Color3 <- NULL
data$PAM..Fv.Fm. <- NULL
data$X <- NULL
#if tank A-D, rep 1; if tank E-F, rep 2
data$Rep[data$Tank == "A"] <- "1"
data$Rep[data$Tank == "B"] <- "1"
data$Rep[data$Tank == "C"] <- "1"
data$Rep[data$Tank == "D"] <- "1"
data$Rep[data$Tank == "E"] <- "2"
data$Rep[data$Tank == "F"] <- "2"
data$Rep[data$Tank == "G"] <- "2"
data$Rep[data$Tank == "H"] <- "2"
data$Tank <- NULL
data_normalized <- spread(data, Ramp, AverageRed)
head(data_normalized)
data_normalized$t35_normalizedto28 <- data_normalized$`35` - data_normalized$`28`
data_normalized$t34_normalizedto28 <- data_normalized$`34` - data_normalized$`28`
data_normalized$t33_normalizedto28 <- data_normalized$`33` - data_normalized$`28`
head(data_normalized)
#now try checking assumptions
#plot data
data_norm <- gather(data_normalized, Ramp, AverageRed, t35_normalizedto28:t33_normalizedto28)
ggplot(data=data_norm, aes(x=Site, y=AverageRed, fill = Ramp))+ geom_boxplot() +
theme_bw() + ylab("Red Intensity \n (normalized to controls at 28C)") + xlab("") + scale_fill_discrete(name = "Treatment", labels = c("33C", "34C", "35C"))  + scale_fill_manual(values = c("dodgerblue4", "springgreen3", "yellow2"), name = "Treatment", labels = c("33C", "34C", "35C"))
#ggsave("t2_red_normalized.pdf", width = 6, height = 4)
#check assumptions
#normality
hist(data_norm$AverageRed) #looks normal!
ggdensity(data_norm$AverageRed) #looks normal
ggqqplot(data_norm$AverageRed) #looks normal!
shapiro.test(data_norm$AverageRed)
#normal!!!!
#equality of variances
bartlett.test(AverageRed ~ Site, data=data_norm)
#not equal
# p = 0.02155
bartlett.test(AverageRed ~ Ramp, data=data_norm)
#equal by ramp
leveneTest(AverageRed ~ Site * Ramp, data=data_norm)
#equal with both
data_norm$AverageRed_log <- as.numeric(log10(data_norm$AverageRed +1))
data_norm$AverageRed_sqrt <- as.numeric(sqrt(data_norm$AverageRed))
bartlett.test(AverageRed_log ~ Site, data=data_norm)
bartlett.test(AverageRed_sqrt ~ Site, data=data_norm)
#does this mean I should sqrt transform data ??
#change this to your working directory
setwd(dir = "~/Desktop/GitHub/CBASS_bleachingdata/")
rm( list = ls())
graphics.off()
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(mosaic)
library(car)
library(lmerTest)
library(emmeans)
library(ggpubr)
library(tidyr)
data <- read.csv("raw data sheets/MasterASData.csv")
head(data)
data$Time.point <- as.character(data$Time.point)
#insert "field" into timepoint for field collected corals
data$Time.point[data$Ramp == "Field"] <- "Field"
#first subset only recovery data (time point 2)
#recovery/time point2 data more likely to show diffs
data_recov <- data %>%
filter(data$Time.point == "Recovery")
#remove NAs
data_recov <- data_recov[!is.na(data_recov$AverageRed), ]
data <- data_recov
data$Coral.Watch.Color1 <- NULL
data$Coral.Watch.Color2 <- NULL
data$Coral.Watch.Color3 <- NULL
data$PAM..Fv.Fm. <- NULL
data$X <- NULL
#if tank A-D, rep 1; if tank E-F, rep 2
data$Rep[data$Tank == "A"] <- "1"
data$Rep[data$Tank == "B"] <- "1"
data$Rep[data$Tank == "C"] <- "1"
data$Rep[data$Tank == "D"] <- "1"
data$Rep[data$Tank == "E"] <- "2"
data$Rep[data$Tank == "F"] <- "2"
data$Rep[data$Tank == "G"] <- "2"
data$Rep[data$Tank == "H"] <- "2"
data$Tank <- NULL
data_normalized <- spread(data, Ramp, AverageRed)
head(data_normalized)
data_normalized$t35_normalizedto28 <- data_normalized$`35` - data_normalized$`28`
data_normalized$t34_normalizedto28 <- data_normalized$`34` - data_normalized$`28`
data_normalized$t33_normalizedto28 <- data_normalized$`33` - data_normalized$`28`
head(data_normalized)
#now try checking assumptions
#plot data
data_norm <- gather(data_normalized, Ramp, AverageRed, t35_normalizedto28:t33_normalizedto28)
ggplot(data=data_norm, aes(x=Site, y=AverageRed, fill = Ramp))+ geom_boxplot() +
theme_bw() + ylab("Red Intensity \n (normalized to controls at 28C)") + xlab("") + scale_fill_discrete(name = "Treatment", labels = c("33C", "34C", "35C"))  + scale_fill_manual(values = c("dodgerblue4", "springgreen3", "yellow2"), name = "Treatment", labels = c("33C", "34C", "35C"))
#ggsave("t2_red_normalized.pdf", width = 6, height = 4)
#check assumptions
#normality
hist(data_norm$AverageRed) #looks normal!
ggdensity(data_norm$AverageRed) #looks normal
ggqqplot(data_norm$AverageRed) #looks normal!
shapiro.test(data_norm$AverageRed)
#normal!!!!
#equality of variances
bartlett.test(AverageRed ~ Site, data=data_norm)
#not equal
# p = 0.02155
bartlett.test(AverageRed ~ Ramp, data=data_norm)
#equal by ramp
leveneTest(AverageRed ~ Site * Ramp, data=data_norm)
#equal with both
data_norm$AverageRed_log <- as.numeric(log10(data_norm$AverageRed +1))
data_norm$AverageRed_sqrt <- as.numeric(sqrt(data_norm$AverageRed))
bartlett.test(AverageRed_log ~ Site, data=data_norm)
bartlett.test(AverageRed_sqrt ~ Site, data=data_norm)
#does this mean I should sqrt transform data ??
# Analysis of variance (2-way) ANOVA CBASS
red.CBASS.lm <- lm(AverageRed ~ Site * Ramp, data = data_norm)
Anova(red.CBASS.lm, type = "III")
#site is not signif (p = 0.7818383)
#temp is signif (p = 0.0004361)
#interaction of site and ramp is not signif (p = 0.3948698)
#since the interaction is not signif, we can run ANOVA without interaction
red.CBASS.lm <- lm(AverageRed ~ Site + Ramp, data = data_norm)
Anova(red.CBASS.lm, type = "III")
#site signif (p = 0.02162)
#temp signif (p = 5.043e-05)
# Model fitting and assumptions diagnostic
plot(AverageRed ~ interaction(Site,Ramp), data = data_norm) # Box-plot homogeneity of variance
#I think this looks mostly okay?
leveneTest(AverageRed ~ Site * Ramp, data=data_norm)
# equal (p = 0.104)
#plot residuals
plot(red.CBASS.lm, 1) # Residual vs Fitted values
qqnorm(resid(red.CBASS.lm)); qqline(resid(red.CBASS.lm))
#mostly normal
hist(resid(red.CBASS.lm))
#looks perfectly normal
shapiro.test(red.CBASS.lm$residuals)
#very normal
#0.7882
# post-hoc test - Meaningful comparisons
# Look for differences of reef sites within each temperature condition
red.CBASS.emms.reef <- emmeans(red.CBASS.lm, pairwise ~ Site|Ramp, type="response", weights = "proportional", adjust="none")
summary(red.CBASS.emms.reef$emmeans)
plot(red.CBASS.emms.reef)
# P.value adjustment of Bonferroni for the aforemention comparisons.
rbind(red.CBASS.emms.reef$contrasts, adjust="bonferroni")
#some are close to significance at 0.09 (Vatia v Fagatele) but none are <0.05?
# so no signif diffs?
#Look for diffs among temps within sites
red.CBASS.emms.reef <- emmeans(red.CBASS.lm, pairwise ~ Ramp|Site, type="response", weights = "proportional", adjust="none")
summary(red.CBASS.emms.reef$emmeans)
plot(red.CBASS.emms.reef)
# P.value adjustment of Bonferroni for the aforemention comparisons.
rbind(red.CBASS.emms.reef$contrasts, adjust="bonferroni")
#33 is diff than 34 and 35 across all sites
# try tukey post hoc
tukey <- TukeyHSD(red.CBASS.lm)
plot(tukey)
tukey
#shows signif diffs for:
#site: vatia-cannery and vatia-fagatele
#temp: 33 is diff than 34 and 35
tukey
